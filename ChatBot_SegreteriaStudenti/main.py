#!/usr/bin/env python3
"""
ChatBot Segreteria Studenti - Tesi Triennale Ingegneria Informatica
Sistema per rispondere automaticamente alle domande degli studenti universitari

Tecnologie utilizzate:
- Sentence Transformers (all-MiniLM-L6-v2) per embedding
- ChromaDB per vector store
- Ollama + Mistral 7B per LLM locale
- RAG (Retrieval-Augmented Generation)
"""

import os
import sys
import re
from datetime import datetime
from dotenv import load_dotenv

# Carica variabili ambiente
load_dotenv()

# Aggiungi il path per gli import
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Import con gestione errori
try:
    from local_embeddings import LocalEmbeddings
    from creazione_vectorstore import search_vectorstore, crea_vectorstore_free
    from ollama_llm import OllamaLLM
    from dividi_chunks import split_text_in_chunks
except ImportError as e:
    print(f"âŒ Errore import moduli: {e}")
    print("Verifica che tutti i file siano presenti in src/")
    print("Esegui: pip install -r requirements.txt")
    sys.exit(1)

class ChatbotRAG:
    """Classe principale del chatbot RAG"""
    
    def __init__(self):
        """Inizializza i componenti del chatbot"""
        print("ğŸ¤– Inizializzazione ChatBot RAG...")
        
        try:
            # Inizializza embedding
            self.embedder = LocalEmbeddings()
            print("âœ… Embeddings caricati")
            
            # Inizializza LLM
            self.llm = OllamaLLM()
            print("âœ… LLM Ollama configurato")
            
            # Verifica connessione Ollama
            if not self.llm.check_connection():
                raise Exception("Ollama non raggiungibile")
            
            print("âœ… ChatBot pronto!")
            
        except Exception as e:
            print(f"âŒ Errore inizializzazione: {e}")
            raise
    
    def retrieve_documents(self, query, k=5):
        """Recupera documenti rilevanti dal vector store"""
        try:
            results = search_vectorstore(query, k=k, embedder=self.embedder)
            
            if not results["documents"] or not results["documents"][0]:
                return []
            
            # Formatta i documenti recuperati
            docs = []
            for doc, distance in zip(results["documents"][0], results["distances"][0]):
                docs.append({
                    "content": doc,
                    "score": distance
                })
            
            return docs
            
        except Exception as e:
            print(f"âš ï¸ Errore nel retrieval: {e}")
            return []
    
    def generate_response(self, query, context_docs):
        """Genera risposta usando LLM con contesto"""
        
        # Costruisci il contesto
        if context_docs:
            context = "\n\n".join([doc["content"] for doc in context_docs[:3]])
        else:
            context = "Non sono riuscito a trovare informazioni specifiche nei documenti."
        
        # Prompt template
        prompt = f"""Sei un assistente virtuale della Segreteria Studenti dell'UniversitÃ  di Bergamo.

CONTESTO DOCUMENTI:
{context}

DOMANDA STUDENTE: {query}

ISTRUZIONI:
- Rispondi in modo preciso e utile basandoti sul CONTESTO fornito
- Se il contesto non contiene informazioni sufficienti, dillo chiaramente
- Mantieni un tono professionale ma cordiale
- Se ci sono link/URL nel contesto, includili nella risposta
- Se la domanda non Ã¨ chiara o troppo generica, chiedi maggiori dettagli
- Se la domanda Ã¨ fuori dal tuo ambito (segreteria studenti), suggerisci di contattare l'ufficio competente

RISPOSTA:"""

        try:
            response = self.llm.generate(prompt)
            return {
                "response": response,
                "context_used": len(context_docs),
                "should_redirect": len(context_docs) == 0 or "non sono riuscito" in response.lower()
            }
            
        except Exception as e:
            print(f"âš ï¸ Errore generazione risposta: {e}")
            return {
                "response": "Mi dispiace, sto avendo difficoltÃ  tecniche. Ti consiglio di contattare direttamente la segreteria studenti.",
                "context_used": 0,
                "should_redirect": True
            }
    
    def chat(self, query):
        """Metodo principale per gestire una query"""
        print(f"ğŸ” Cercando informazioni per: '{query}'")
        
        # Recupera documenti
        docs = self.retrieve_documents(query)
        print(f"ğŸ“š Trovati {len(docs)} documenti rilevanti")
        
        # Genera risposta
        result = self.generate_response(query, docs)
        
        return result

def check_requirements():
    """Verifica requisiti minimi per il funzionamento"""
    print("ğŸ” Verifica sistema...")
    
    checks = []
    
    # Verifica Ollama
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            has_mistral = any('mistral' in model.get('name', '') for model in models)
            if has_mistral:
                checks.append("âœ… Ollama + Mistral: Pronti")
            else:
                checks.append("âš ï¸ Ollama: Attivo, ma Mistral mancante")
                checks.append("   â†’ Esegui: ollama pull mistral:7b")
        else:
            checks.append("âŒ Ollama: Non risponde")
    except:
        checks.append("âŒ Ollama: Non in esecuzione")
        checks.append("   â†’ Avvia Ollama e scarica Mistral")
    
    # Verifica vectorstore
    if os.path.exists("vectordb") and os.listdir("vectordb"):
        checks.append("âœ… Database vettoriale: Presente")
    else:
        checks.append("âŒ Database vettoriale: Mancante")
        checks.append("   â†’ Esegui: python src/creazione_vectorstore.py")
    
    # Verifica documenti estratti
    if os.path.exists("data/testi_estratti") and os.listdir("data/testi_estratti"):
        checks.append("âœ… Documenti estratti: Presenti")
    else:
        checks.append("âŒ Documenti estratti: Mancanti")
        checks.append("   â†’ Esegui: python src/testi_estratti.py")
    
    for check in checks:
        print(f"  {check}")
    
    has_errors = any("âŒ" in check for check in checks)
    if has_errors:
        print(f"\nâš ï¸ Sistema non pronto. Risolvi gli errori sopra.")
        return False
        
    return True

def setup_chatbot():
    """Inizializza il chatbot con tutti i controlli"""
    try:
        chatbot = ChatbotRAG()
        return chatbot
    except Exception as e:
        print(f"âŒ Impossibile inizializzare il chatbot: {e}")
        return None

def chatbot_cli():
    """Interfaccia a riga di comando per il chatbot"""
    
    if not check_requirements():
        return False
    
    print("\nğŸ¤– Avvio ChatBot...")
    chatbot = setup_chatbot()
    
    if not chatbot:
        print("âŒ Impossibile avviare il chatbot")
        return False
    
    print("\n" + "=" * 60)
    print("ğŸ“ CHATBOT SEGRETERIA STUDENTI UNIBG")
    print("=" * 60)
    print("Fai una domanda sull'universitÃ !")
    print("Comandi: 'help' per esempi | 'exit' per uscire")
    print("=" * 60)
    
    while True:
        print("\n" + "-" * 40)
        try:
            domanda = input("ğŸ§‘â€ğŸ“ Studente > ").strip()
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Arrivederci!")
            break
        
        if domanda.lower() in ['exit', 'quit', 'bye', 'esci']:
            print("ğŸ‘‹ Arrivederci!")
            break
            
        elif domanda.lower() == 'help':
            show_help()
            continue
            
        elif not domanda:
            print("ğŸ’¬ Scrivi una domanda per iniziare.")
            continue
        
        try:
            print("ğŸ”„ Elaborazione...")
            result = chatbot.chat(domanda)
            response = result['response']
            
            # Evidenzia URL nella risposta
            url_pattern = r'(https?://[^\s<>"{}|\\^`\[\]]+)'
            highlighted_response = re.sub(url_pattern, r'ğŸ”— \1', response)
            
            print(f"\nğŸ¤– ChatBot: {highlighted_response}")
            
            # Info aggiuntive
            if result['context_used'] > 0:
                print(f"ğŸ“Š (Basato su {result['context_used']} documenti)")
            
            if result['should_redirect']:
                ticket_url = os.getenv('TICKET_URL', 'https://helpdesk.unibg.it/')
                print(f"\nğŸ’¡ Per assistenza personalizzata: ğŸ”— {ticket_url}")
                
        except Exception as e:
            print(f"âŒ Errore nel processare la richiesta: {str(e)}")
            print("ğŸ“ Ti consiglio di contattare direttamente la Segreteria:")
            print(f"ğŸ”— {os.getenv('TICKET_URL', 'https://helpdesk.unibg.it/')}")
    
    return True

def show_help():
    """Mostra esempi di domande che il chatbot puÃ² gestire"""
    print("\n" + "=" * 50)
    print("ğŸ“š ESEMPI DI DOMANDE")
    print("=" * 50)
    
    esempi = [
        "ğŸ“ Come faccio a iscrivermi agli esami?",
        "ğŸ’° Quando devo pagare le tasse universitarie?",
        "ğŸ“„ Come richiedo un certificato di laurea?",
        "ğŸ“ Che documenti servono per la laurea?",
        "ğŸ“ Quali sono i contatti della segreteria?",
        "â™¿ Come funziona il servizio disabilitÃ ?",
        "ğŸ’¼ Come trovo informazioni sui tirocini?",
        "ğŸ¢ Quali sono gli orari degli uffici?",
        "ğŸ“‹ Come funziona l'immatricolazione?",
        "ğŸ“š Dove trovo il piano di studi?"
    ]
    
    for esempio in esempi:
        print(f"  â€¢ {esempio}")
    
    print("\nğŸ’¡ Puoi fare domande su qualsiasi aspetto della vita universitaria!")

def show_setup_instructions():
    """Mostra istruzioni per il setup iniziale"""
    print("\n" + "=" * 50)
    print("ğŸ› ï¸ SETUP DEL SISTEMA")
    print("=" * 50)
    
    print("STEP 1 - Installa Ollama:")
    print("  â€¢ Scarica da: https://ollama.ai")
    print("  â€¢ Installa e avvia il servizio")
    print("")
    
    print("STEP 2 - Scarica il modello:")
    print("  â€¢ Esegui: ollama pull mistral:7b")
    print("")
    
    print("STEP 3 - Installa dipendenze Python:")
    print("  â€¢ Esegui: pip install -r requirements.txt")
    print("")
    
    print("STEP 4 - Prepara i dati:")
    print("  â€¢ Estrai testi: python src/testi_estratti.py")
    print("  â€¢ Crea database: python src/creazione_vectorstore.py")
    print("")
    
    print("STEP 5 - Avvia il chatbot:")
    print("  â€¢ Esegui: python main.py")

def main():
    """Funzione principale"""
    print("ğŸ“ ChatBot Segreteria Studenti - UniBg")
    print(f"ğŸ“… Avviato il {datetime.now().strftime('%d/%m/%Y alle %H:%M')}")
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--setup":
            show_setup_instructions()
            return
        elif sys.argv[1] == "--check":
            check_requirements()
            return
        elif sys.argv[1] == "--help":
            print("\n" + "=" * 40)
            print("ğŸ“– COMANDI DISPONIBILI")
            print("=" * 40)
            print("  python main.py           # Avvia chatbot")
            print("  python main.py --setup   # Mostra istruzioni setup")  
            print("  python main.py --check   # Verifica sistema")
            print("  python main.py --help    # Mostra questo aiuto")
            return
    
    # Avvia l'interfaccia CLI
    chatbot_cli()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Programma interrotto dall'utente. Arrivederci!")
    except Exception as e:
        print(f"\nâŒ Errore critico: {e}")
        print("ğŸ”§ Verifica il setup con: python main.py --check")